import React from 'react';
import { Calculator, TrendingUp, RefreshCw } from 'lucide-react';
import Header from '~/components/ui/Header';
import Footer from '~/components/ui/Footer';
import { ThemeSelector } from '~/components/ui';

const AiTokenBurnRates = () => {
  return (
    <div className="min-h-screen bg-gray-50 transition-colors duration-200 dark:bg-gray-900">
      <Header />
      <div className="fixed bottom-0 left-0 md:m-4">
        <ThemeSelector />
      </div>
      <div className="mx-auto max-w-7xl px-4 py-12 sm:px-6 lg:px-8">
        <div className="space-y-8">
          {/* Header Section */}
          <div className="space-y-4 text-center">
            <h1 className="text-4xl font-bold text-gray-900 dark:text-gray-50">
              Understanding Token Consumption
            </h1>
            <p className="mx-auto max-w-2xl text-lg text-gray-600 dark:text-gray-300">
              Tokens are used whenever you interact with language models on our platform. Upon
              selecting a model, you will see its Input and Output multipliers.
            </p>
          </div>

          {/* Main Content */}
          <div className="grid gap-8 md:grid-cols-2">
            {/* Token Calculation Section */}
            <div className="rounded-lg border border-gray-200 bg-white p-6 shadow-sm dark:border-gray-700 dark:bg-gray-800">
              <div className="mb-6">
                <h2 className="flex flex-col items-center gap-3 text-2xl font-semibold text-gray-900 dark:text-gray-50 sm:flex-row sm:gap-2">
                  <Calculator className="h-8 w-8 sm:h-6 sm:w-6" />
                  Token Calculation
                </h2>
              </div>
              <div className="space-y-4">
                <div className="space-y-2">
                  <h3 className="font-semibold text-gray-900 dark:text-gray-50">Input Tokens</h3>
                  <p className="text-gray-600 dark:text-gray-300">
                    Input tokens are derived from your prompt and the context of your ongoing
                    conversation. They are multiplied by the Input rate.
                  </p>
                </div>
                <div className="space-y-2">
                  <h3 className="font-semibold text-gray-900 dark:text-gray-50">Output Tokens</h3>
                  <p className="text-gray-600 dark:text-gray-300">
                    Output tokens are generated by the model's response and multiplied by the Output
                    rate.
                  </p>
                </div>
                <div className="mt-4 rounded-md bg-blue-50 p-4 dark:bg-blue-900/30">
                  <p className="text-sm text-blue-700 dark:text-blue-300">
                    For example, if a model's Input rate is 2.13 and Output rate is 8.5, each input
                    token consumes 2.13 tokens, and each output token consumes 8.5 tokens.
                  </p>
                </div>
              </div>
            </div>

            {/* Tips Section */}
            <div className="rounded-lg border border-gray-200 bg-white p-6 shadow-sm dark:border-gray-700 dark:bg-gray-800">
              <div className="mb-6">
                <h2 className="flex flex-col items-center gap-3 text-2xl font-semibold text-gray-900 dark:text-gray-50 sm:flex-row sm:gap-2">
                  <TrendingUp className="hidden text-green-500 sm:block sm:h-6 sm:w-6" />
                  Tips to Optimize Token Usage
                </h2>
              </div>
              <div className="space-y-6">
                <div className="flex flex-col items-center gap-3 sm:flex-row sm:items-start">
                  <RefreshCw className="h-8 w-8 text-green-500 sm:mt-1 sm:h-6 sm:w-6" />
                  <div>
                    <h3 className="text-center font-semibold text-gray-900 dark:text-gray-50 sm:text-left">
                      Start a New Chat for Each Topic
                    </h3>
                    <p className="text-center text-gray-600 dark:text-gray-300 sm:text-left">
                      Context is treated as part of your input, so longer threads consume more
                      tokens. Starting a new chat for each topic helps reduce unnecessary input
                      token usage.
                    </p>
                  </div>
                </div>

                <div className="flex flex-col items-center gap-3 sm:flex-row sm:items-start">
                  <TrendingUp className="h-8 w-8 text-green-500 sm:mt-1 sm:h-6 sm:w-6" />
                  <div>
                    <h3 className="text-center font-semibold text-gray-900 dark:text-gray-50 sm:text-left">
                      Use Models Strategically
                    </h3>
                    <p className="text-center text-gray-600 dark:text-gray-300 sm:text-left">
                      Experiment with different models to find the best balance between cost and
                      performance.
                    </p>
                  </div>
                </div>

                <div className="flex flex-col items-center gap-3 sm:flex-row sm:items-start">
                  <Calculator className="h-8 w-8 text-green-500 sm:mt-1 sm:h-6 sm:w-6" />
                  <div>
                    <h3 className="text-center font-semibold text-gray-900 dark:text-gray-50 sm:text-left">
                      Understand Multipliers
                    </h3>
                    <p className="text-center text-gray-600 dark:text-gray-300 sm:text-left">
                      Higher multipliers (e.g., for powerful models like Claude 3 Opus or OpenAI's
                      o1) may cost more but often deliver better performance.
                    </p>
                  </div>
                </div>
              </div>
            </div>
          </div>

          {/* Footer Note */}
          <div className="mt-8 text-center">
            <p className="mx-auto max-w-2xl text-sm text-gray-600 dark:text-gray-300">
              By being mindful of your token consumption and using these strategies, you can
              efficiently manage your usage and costs while enjoying the full capabilities of our
              platform.
            </p>
          </div>
        </div>
      </div>
      <Footer />
    </div>
  );
};

export default AiTokenBurnRates;
